{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 得到CaseStudy需要的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1\n",
       "0  0  984\n",
       "1  0  985\n",
       "2  0  986\n",
       "3  1  987\n",
       "4  1  988"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "Cdata = pd.read_csv(\"data/Drug_Protein_Num.csv\",header=None)\n",
    "Cdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>protein</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>984</td>\n",
       "      <td>9606.ensp00000364709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>985</td>\n",
       "      <td>9606.ensp00000364731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>986</td>\n",
       "      <td>9606.ensp00000233838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>987</td>\n",
       "      <td>9606.ensp00000410294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>988</td>\n",
       "      <td>9606.ensp00000393312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0               protein\n",
       "0         984  9606.ensp00000364709\n",
       "1         985  9606.ensp00000364731\n",
       "2         986  9606.ensp00000233838\n",
       "3         987  9606.ensp00000410294\n",
       "4         988  9606.ensp00000393312"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pr_name = pd.read_csv('data/protein_name.csv')\n",
    "Pr_name.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PrID</th>\n",
       "      <th>protein</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>984</td>\n",
       "      <td>9606.ensp00000364709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>985</td>\n",
       "      <td>9606.ensp00000364731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>986</td>\n",
       "      <td>9606.ensp00000233838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>987</td>\n",
       "      <td>9606.ensp00000410294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>988</td>\n",
       "      <td>9606.ensp00000393312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PrID               protein\n",
       "0   984  9606.ensp00000364709\n",
       "1   985  9606.ensp00000364731\n",
       "2   986  9606.ensp00000233838\n",
       "3   987  9606.ensp00000410294\n",
       "4   988  9606.ensp00000393312"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pr_name = Pr_name.rename(columns={'Unnamed: 0': 'PrID'})\n",
    "Pr_name.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 输入所要研究的Drug编号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DrugID</th>\n",
       "      <th>PrID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>320</td>\n",
       "      <td>984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>320</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>320</td>\n",
       "      <td>986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>320</td>\n",
       "      <td>987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>320</td>\n",
       "      <td>988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DrugID  PrID\n",
       "0     320   984\n",
       "1     320   985\n",
       "2     320   986\n",
       "3     320   987\n",
       "4     320   988"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 本次使用的Drug有：Risperidone db00734 275; Haloperidol db00502 182 \n",
    "# Clozapine DB00363 120\n",
    "# Pioglitazone DB01132 436\n",
    "# Caffeine  DB00201 56\n",
    "# drug_list = [275,182]\n",
    "#drug_list = [56,120,436]\n",
    "import numpy as np\n",
    "drug_list = list(np.random.randint(0, 985, 985)) ## 选取全部进行训练\n",
    "global Full_Case_data\n",
    "Full_Case_data = pd.DataFrame()\n",
    "for i in drug_list:\n",
    "    Case_data= Cdata.loc[Cdata[0] == i]\n",
    "    Case_data = Case_data.rename(columns={1: 'PrID'})\n",
    "    dd2 = pd.merge(Pr_name,Case_data,how='left',on='PrID')\n",
    "    dd2 = dd2[~dd2[0].isin([i])]\n",
    "    dd2 = dd2.drop(['protein',0],axis=1)\n",
    "    dd2['DrugID']=i\n",
    "    dd2.insert(0, 'DrugID', dd2.pop('DrugID'))\n",
    "    Full_Case_data = pd.concat([Full_Case_data, dd2], ignore_index=True)\n",
    "Full_Case_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Full_Case_data.to_csv('data/Casestudy_Num_all.csv',header=0,index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算GCN Feaure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 导入特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.007599</td>\n",
       "      <td>-0.007655</td>\n",
       "      <td>-0.003703</td>\n",
       "      <td>-0.007203</td>\n",
       "      <td>0.002032</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.005779</td>\n",
       "      <td>-0.008866</td>\n",
       "      <td>-0.00496</td>\n",
       "      <td>0.005712</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005631</td>\n",
       "      <td>0.002488</td>\n",
       "      <td>-0.013618</td>\n",
       "      <td>-0.008738</td>\n",
       "      <td>0.007777</td>\n",
       "      <td>0.005095</td>\n",
       "      <td>0.00378</td>\n",
       "      <td>-0.015584</td>\n",
       "      <td>-0.005586</td>\n",
       "      <td>0.004156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.007599</td>\n",
       "      <td>-0.007655</td>\n",
       "      <td>-0.003703</td>\n",
       "      <td>-0.007203</td>\n",
       "      <td>0.002032</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.005779</td>\n",
       "      <td>-0.008866</td>\n",
       "      <td>-0.00496</td>\n",
       "      <td>0.005712</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005631</td>\n",
       "      <td>0.002488</td>\n",
       "      <td>-0.013618</td>\n",
       "      <td>-0.008738</td>\n",
       "      <td>0.007777</td>\n",
       "      <td>0.005095</td>\n",
       "      <td>0.00378</td>\n",
       "      <td>-0.015584</td>\n",
       "      <td>-0.005586</td>\n",
       "      <td>0.004156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.007599</td>\n",
       "      <td>-0.007655</td>\n",
       "      <td>-0.003703</td>\n",
       "      <td>-0.007203</td>\n",
       "      <td>0.002032</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.005779</td>\n",
       "      <td>-0.008866</td>\n",
       "      <td>-0.00496</td>\n",
       "      <td>0.005712</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005631</td>\n",
       "      <td>0.002488</td>\n",
       "      <td>-0.013618</td>\n",
       "      <td>-0.008738</td>\n",
       "      <td>0.007777</td>\n",
       "      <td>0.005095</td>\n",
       "      <td>0.00378</td>\n",
       "      <td>-0.015584</td>\n",
       "      <td>-0.005586</td>\n",
       "      <td>0.004156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.007599</td>\n",
       "      <td>-0.007655</td>\n",
       "      <td>-0.003703</td>\n",
       "      <td>-0.007203</td>\n",
       "      <td>0.002032</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.005779</td>\n",
       "      <td>-0.008866</td>\n",
       "      <td>-0.00496</td>\n",
       "      <td>0.005712</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005631</td>\n",
       "      <td>0.002488</td>\n",
       "      <td>-0.013618</td>\n",
       "      <td>-0.008738</td>\n",
       "      <td>0.007777</td>\n",
       "      <td>0.005095</td>\n",
       "      <td>0.00378</td>\n",
       "      <td>-0.015584</td>\n",
       "      <td>-0.005586</td>\n",
       "      <td>0.004156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.180584</td>\n",
       "      <td>0.526513</td>\n",
       "      <td>0.793145</td>\n",
       "      <td>-0.245426</td>\n",
       "      <td>-0.220634</td>\n",
       "      <td>0.559357</td>\n",
       "      <td>1.059898</td>\n",
       "      <td>0.148331</td>\n",
       "      <td>-0.98174</td>\n",
       "      <td>-0.789687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003815</td>\n",
       "      <td>-0.553314</td>\n",
       "      <td>0.003378</td>\n",
       "      <td>0.335591</td>\n",
       "      <td>0.143528</td>\n",
       "      <td>-1.134055</td>\n",
       "      <td>0.62961</td>\n",
       "      <td>0.330191</td>\n",
       "      <td>0.377519</td>\n",
       "      <td>-0.798777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         1         2         3         4         5         6         7   \\\n",
       "0 -0.007599 -0.007655 -0.003703 -0.007203  0.002032  0.006483  0.005779   \n",
       "1 -0.007599 -0.007655 -0.003703 -0.007203  0.002032  0.006483  0.005779   \n",
       "2 -0.007599 -0.007655 -0.003703 -0.007203  0.002032  0.006483  0.005779   \n",
       "3 -0.007599 -0.007655 -0.003703 -0.007203  0.002032  0.006483  0.005779   \n",
       "4  1.180584  0.526513  0.793145 -0.245426 -0.220634  0.559357  1.059898   \n",
       "\n",
       "         8        9         10  ...        55        56        57        58  \\\n",
       "0 -0.008866 -0.00496  0.005712  ... -0.005631  0.002488 -0.013618 -0.008738   \n",
       "1 -0.008866 -0.00496  0.005712  ... -0.005631  0.002488 -0.013618 -0.008738   \n",
       "2 -0.008866 -0.00496  0.005712  ... -0.005631  0.002488 -0.013618 -0.008738   \n",
       "3 -0.008866 -0.00496  0.005712  ... -0.005631  0.002488 -0.013618 -0.008738   \n",
       "4  0.148331 -0.98174 -0.789687  ...  0.003815 -0.553314  0.003378  0.335591   \n",
       "\n",
       "         59        60       61        62        63        64  \n",
       "0  0.007777  0.005095  0.00378 -0.015584 -0.005586  0.004156  \n",
       "1  0.007777  0.005095  0.00378 -0.015584 -0.005586  0.004156  \n",
       "2  0.007777  0.005095  0.00378 -0.015584 -0.005586  0.004156  \n",
       "3  0.007777  0.005095  0.00378 -0.015584 -0.005586  0.004156  \n",
       "4  0.143528 -1.134055  0.62961  0.330191  0.377519 -0.798777  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_features = pd.read_csv('data/Drug_Protein_Attribute.csv',header = None) \n",
    "node_features = node_features.iloc[:,1:]\n",
    "node_features.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    0.0\n",
       "2    0.0\n",
       "3    0.0\n",
       "4    0.0\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### 设置标签\n",
    "import numpy as np\n",
    "DTIs= pd.read_csv('data/Drug_Protein_Num.csv',header = None) \n",
    "labels = pd.DataFrame(np.random.rand(max(DTIs[1])+1,1))#pd.DataFrame(np.random.rand(max(NLMI_num),1))\n",
    "labels[0:max(DTIs[0])+1]=0\n",
    "labels[max(DTIs[0])+1:]=1\n",
    "labels = labels[0] # 提取节点标签列\n",
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建初始的邻接矩阵 #('./data/DDI_train'+str(i)+'.csv')\n",
    "def load_file_as_Adj_matrix(filename):\n",
    "    import scipy.sparse as sp\n",
    "    DTIs_train = pd.read_csv(filename,header=None)\n",
    "    if max(DTIs_train[1]) != 1618:\n",
    "        relation_matrix = np.zeros((1618+1,1618+1))\n",
    "    else:\n",
    "        relation_matrix = np.zeros((max(DTIs_train[1]+1),max(DTIs_train[1]+1)))\n",
    "    for i, j in np.array(DTIs_train):\n",
    "        lnc, mi = int(i), int(j)\n",
    "        relation_matrix[lnc, mi] = 1\n",
    "    Adj = sp.csr_matrix(relation_matrix, dtype=np.float32)\n",
    "    return Adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建GCN训练需要的邻接方阵\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "def load_data(adj,node_features,node_labels):\n",
    "  features = sp.csr_matrix(node_features, dtype=np.float32)  # 储存为csr型稀疏矩阵\n",
    "  # build symmetric adjacency matrix   论文里A^=(D~)^0.5 A~ (D~)^0.5这个公式\n",
    "  # adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
    "  # 对于无向图，邻接矩阵是对称的。上一步得到的adj是按有向图构建的，转换成无向图的邻接矩阵需要扩充成对称矩阵\n",
    "  features = normalize(features)\n",
    "  adj = normalize(adj + sp.eye(adj.shape[0]))   # eye创建单位矩阵，第一个参数为行数，第二个为列数\n",
    "  # 对应公式A~=A+IN\n",
    "  # 分别构建训练集、验证集、测试集，并创建特征矩阵、标签向量和邻接矩阵的tensor，用来做模型的输入\n",
    "  idx_train = range(500)\n",
    "  idx_val = range(500, 660)\n",
    "  idx_test = range(660, int(adj.shape[0]))  \n",
    "  features = torch.FloatTensor(np.array(features.todense()))  # tensor为pytorch常用的数据结构\n",
    "  labels = torch.LongTensor(np.array(node_labels))\n",
    "  adj = sparse_mx_to_torch_sparse_tensor(adj)   # 邻接矩阵转为tensor处理\n",
    "  idx_train = torch.LongTensor(idx_train)\n",
    "  idx_val = torch.LongTensor(idx_val)\n",
    "  idx_test = torch.LongTensor(idx_test)\n",
    "  return adj, features, labels, idx_train, idx_val, idx_test  \n",
    "def normalize(mx):\n",
    "  \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "  rowsum = np.array(mx.sum(1))  # 对每一行求和\n",
    "  r_inv = np.power(rowsum, -1).flatten()  # 求倒数\n",
    "  r_inv[np.isinf(r_inv)] = 0.  # 如果某一行全为0，则r_inv算出来会等于无穷大，将这些行的r_inv置为0\n",
    "  r_mat_inv = sp.diags(r_inv)  # 构建对角元素为r_inv的对角矩阵\n",
    "  mx = r_mat_inv.dot(mx)\n",
    "  # 用对角矩阵与原始矩阵的点积起到标准化的作用，原始矩阵中每一行元素都会与对应的r_inv相乘，最终相当于除以了sum\n",
    "  return mx\n",
    "\n",
    "def accuracy(output, labels):\n",
    "  preds = output.max(1)[1].type_as(labels) # 使用type_as(tesnor)将张量转换为给定类型的张量。\n",
    "  correct = preds.eq(labels).double()  # 记录等于preds的label eq:equal\n",
    "  correct = correct.sum()\n",
    "  return correct / len(labels)\n",
    "\n",
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx):    # 把一个sparse matrix转为torch稀疏张量\n",
    "  \"\"\"\n",
    "  numpy中的ndarray转化成pytorch中的tensor : torch.from_numpy()\n",
    "  pytorch中的tensor转化成numpy中的ndarray : numpy()\n",
    "  \"\"\"\n",
    "  sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "  indices = torch.from_numpy(np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
    "  # 不懂的可以去看看COO性稀疏矩阵的结构\n",
    "  values = torch.from_numpy(sparse_mx.data)\n",
    "  shape = torch.Size(sparse_mx.shape)\n",
    "  return torch.sparse.FloatTensor(indices, values, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "\n",
    "class GraphConvolution(Module):\n",
    "\n",
    "    # 初始化层：输入feature，输出feature，权重，偏移\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))  # FloatTensor建立tensor\n",
    "        # 常见用法self.v = torch.nn.Parameter(torch.FloatTensor(hidden_size))：\n",
    "        # 首先可以把这个函数理解为类型转换函数，将一个不可训练的类型Tensor转换成可以训练的类型parameter并将这个parameter\n",
    "        # 绑定到这个module里面，所以经过类型转换这个self.v变成了模型的一部分，成为了模型中根据训练可以改动的参数了。\n",
    "        # 使用这个函数的目的也是想让某些变量在学习的过程中不断的修改其值以达到最优化。\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "            # Parameters与register_parameter都会向parameters写入参数，但是后者可以支持字符串命名\n",
    "        self.reset_parameters()\n",
    "\n",
    "    # 初始化权重\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        # size()函数主要是用来统计矩阵元素个数，或矩阵某一维上的元素个数的函数  size（1）为行\n",
    "        self.weight.data.uniform_(-stdv, stdv)  # uniform() 方法将随机生成下一个实数，它在 [x, y] 范围内\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    '''\n",
    "    前馈运算 即计算A~ X W(0)\n",
    "    input X与权重W相乘，然后adj矩阵与他们的积稀疏乘\n",
    "    直接输入与权重之间进行torch.mm操作，得到support，即XW\n",
    "    support与adj进行torch.spmm操作，得到output，即AXW选择是否加bias\n",
    "    '''\n",
    "    def forward(self, input, adj):\n",
    "        support = torch.mm(input, self.weight)\n",
    "        # torch.mm(a, b)是矩阵a和b矩阵相乘，torch.mul(a, b)是矩阵a和b对应位相乘，a和b的维度必须相等\n",
    "        output = torch.spmm(adj, support)\n",
    "        if self.bias is not None:\n",
    "            return output + self.bias \n",
    "        else:\n",
    "            return output\n",
    "#通过设置断点，可以看出output的形式是0.01，0.01，0.01，0.01，0.01，#0.01，0.94]，里面的值代表该x对应标签不同的概率，故此值可转换为#[0,0,0,0,0,0,1]，对应我们之前把标签onthot后的第七种标签\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_features) + ' -> ' \\\n",
    "               + str(self.out_features) + ')'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class GCN(nn.Module):\n",
    "  def __init__(self, nfeat, nhid, nclass, dropout):\n",
    "    # 底层节点的参数，feature的个数；隐层节点个数；最终的分类数\n",
    "    super(GCN, self).__init__()  #  super()._init_()在利用父类里的对象构造函数\n",
    "    self.gc1 = GraphConvolution(nfeat, nhid)   # gc1输入尺寸nfeat，输出尺寸nhid\n",
    "    self.gc2 = GraphConvolution(nhid, nclass)  # gc2输入尺寸nhid，输出尺寸ncalss\n",
    "    self.dropout = dropout\n",
    "    self.weight = Parameter(torch.FloatTensor(nfeat, nhid))  # FloatTensor建立tensor\n",
    "    # 输入分别是特征和邻接矩阵。最后输出为输出层做log_softmax变换的结果\n",
    "  def forward(self, x, adj):\n",
    "    x = F.relu(self.gc1(x, adj))   # adj即公式Z=softmax(A~Relu(A~XW(0))W(1))中的A~\n",
    "    x2 = F.dropout(x, self.dropout, training = self.training)  # x要dropout\n",
    "    x2 = self.gc2(x2, adj)\n",
    "    return F.log_softmax(x2, dim = 1), x2   #, x  # 参数dim=1表示对每一行求softmax，那么每一行的值加起来都等于1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.011319</td>\n",
       "      <td>-0.304855</td>\n",
       "      <td>-0.022537</td>\n",
       "      <td>0.087194</td>\n",
       "      <td>0.109445</td>\n",
       "      <td>-0.083194</td>\n",
       "      <td>-0.065568</td>\n",
       "      <td>-0.269615</td>\n",
       "      <td>0.055453</td>\n",
       "      <td>-0.022204</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005631</td>\n",
       "      <td>0.002488</td>\n",
       "      <td>-0.013618</td>\n",
       "      <td>-0.008738</td>\n",
       "      <td>0.007777</td>\n",
       "      <td>0.005095</td>\n",
       "      <td>0.00378</td>\n",
       "      <td>-0.015584</td>\n",
       "      <td>-0.005586</td>\n",
       "      <td>0.004156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.014741</td>\n",
       "      <td>-0.296850</td>\n",
       "      <td>-0.023544</td>\n",
       "      <td>0.082032</td>\n",
       "      <td>0.102421</td>\n",
       "      <td>-0.084746</td>\n",
       "      <td>-0.063508</td>\n",
       "      <td>-0.270648</td>\n",
       "      <td>0.052009</td>\n",
       "      <td>-0.010894</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005631</td>\n",
       "      <td>0.002488</td>\n",
       "      <td>-0.013618</td>\n",
       "      <td>-0.008738</td>\n",
       "      <td>0.007777</td>\n",
       "      <td>0.005095</td>\n",
       "      <td>0.00378</td>\n",
       "      <td>-0.015584</td>\n",
       "      <td>-0.005586</td>\n",
       "      <td>0.004156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.021635</td>\n",
       "      <td>-0.311339</td>\n",
       "      <td>-0.025001</td>\n",
       "      <td>0.071055</td>\n",
       "      <td>0.116763</td>\n",
       "      <td>-0.082646</td>\n",
       "      <td>-0.068157</td>\n",
       "      <td>-0.274070</td>\n",
       "      <td>0.046882</td>\n",
       "      <td>-0.005360</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005631</td>\n",
       "      <td>0.002488</td>\n",
       "      <td>-0.013618</td>\n",
       "      <td>-0.008738</td>\n",
       "      <td>0.007777</td>\n",
       "      <td>0.005095</td>\n",
       "      <td>0.00378</td>\n",
       "      <td>-0.015584</td>\n",
       "      <td>-0.005586</td>\n",
       "      <td>0.004156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000605</td>\n",
       "      <td>-0.302556</td>\n",
       "      <td>-0.033224</td>\n",
       "      <td>0.092538</td>\n",
       "      <td>0.108618</td>\n",
       "      <td>-0.089233</td>\n",
       "      <td>-0.052742</td>\n",
       "      <td>-0.272499</td>\n",
       "      <td>0.050293</td>\n",
       "      <td>-0.032407</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005631</td>\n",
       "      <td>0.002488</td>\n",
       "      <td>-0.013618</td>\n",
       "      <td>-0.008738</td>\n",
       "      <td>0.007777</td>\n",
       "      <td>0.005095</td>\n",
       "      <td>0.00378</td>\n",
       "      <td>-0.015584</td>\n",
       "      <td>-0.005586</td>\n",
       "      <td>0.004156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003028</td>\n",
       "      <td>-0.302128</td>\n",
       "      <td>-0.027671</td>\n",
       "      <td>0.099886</td>\n",
       "      <td>0.118802</td>\n",
       "      <td>-0.080713</td>\n",
       "      <td>-0.055088</td>\n",
       "      <td>-0.278225</td>\n",
       "      <td>0.057023</td>\n",
       "      <td>-0.026456</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003815</td>\n",
       "      <td>-0.553314</td>\n",
       "      <td>0.003378</td>\n",
       "      <td>0.335591</td>\n",
       "      <td>0.143528</td>\n",
       "      <td>-1.134055</td>\n",
       "      <td>0.62961</td>\n",
       "      <td>0.330191</td>\n",
       "      <td>0.377519</td>\n",
       "      <td>-0.798777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.011319 -0.304855 -0.022537  0.087194  0.109445 -0.083194 -0.065568   \n",
       "1 -0.014741 -0.296850 -0.023544  0.082032  0.102421 -0.084746 -0.063508   \n",
       "2 -0.021635 -0.311339 -0.025001  0.071055  0.116763 -0.082646 -0.068157   \n",
       "3  0.000605 -0.302556 -0.033224  0.092538  0.108618 -0.089233 -0.052742   \n",
       "4  0.003028 -0.302128 -0.027671  0.099886  0.118802 -0.080713 -0.055088   \n",
       "\n",
       "         7         8         9   ...        55        56        57        58  \\\n",
       "0 -0.269615  0.055453 -0.022204  ... -0.005631  0.002488 -0.013618 -0.008738   \n",
       "1 -0.270648  0.052009 -0.010894  ... -0.005631  0.002488 -0.013618 -0.008738   \n",
       "2 -0.274070  0.046882 -0.005360  ... -0.005631  0.002488 -0.013618 -0.008738   \n",
       "3 -0.272499  0.050293 -0.032407  ... -0.005631  0.002488 -0.013618 -0.008738   \n",
       "4 -0.278225  0.057023 -0.026456  ...  0.003815 -0.553314  0.003378  0.335591   \n",
       "\n",
       "         59        60       61        62        63        64  \n",
       "0  0.007777  0.005095  0.00378 -0.015584 -0.005586  0.004156  \n",
       "1  0.007777  0.005095  0.00378 -0.015584 -0.005586  0.004156  \n",
       "2  0.007777  0.005095  0.00378 -0.015584 -0.005586  0.004156  \n",
       "3  0.007777  0.005095  0.00378 -0.015584 -0.005586  0.004156  \n",
       "4  0.143528 -1.134055  0.62961  0.330191  0.377519 -0.798777  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training settings\n",
    "learning_rate = 0.01\n",
    "weight_decay = 5e-4\n",
    "epoch_num = 200\n",
    "dropout = 0.02\n",
    "#in_size = node_features  #设置输入层的维数\n",
    "hi_size = 64 # 16 #设置隐藏层的维数\n",
    "\n",
    "Adj = load_file_as_Adj_matrix('data/Drug_Protein_Num.csv')\n",
    "adj, train_features, trian_labels, idx_train, idx_val, idx_test = load_data(Adj,node_features,labels)\n",
    "model = GCN(nfeat=train_features.shape[1],\n",
    "        nhid=hi_size,\n",
    "        nclass= 16,#labels.max().item() + 1,\n",
    "        dropout=dropout)\n",
    "model.train()\n",
    "global Emdebding_train, output\n",
    "output, Emdebding_train = model(train_features, adj)\n",
    "Emdebding_GCN = pd.DataFrame(Emdebding_train.detach().numpy())\n",
    "GCN_A = pd.concat([Emdebding_GCN, node_features], axis=1)\n",
    "GCN_A.to_csv('casestudy/data/Emdebding_GCN.csv', header=None,index=False)\n",
    "del Adj, adj, train_features, trian_labels, idx_train, idx_val, idx_test, output\n",
    "GCN_A.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 导入节点的GCN_Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1619"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GCN_data = pd.read_csv('casestudy/data/Emdebding_GCN.csv',header=None)\n",
    "GCN_data.head()\n",
    "len(GCN_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'casestudy/data/Embedding_grarep.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 导入节点的Embedding_DeepWalk\u001b[39;00m\n\u001b[32m      2\u001b[39m E_filename = \u001b[33m'\u001b[39m\u001b[33mcasestudy/data/Embedding_grarep.txt\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m Embedding_Node2vec = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mE_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m Embedding_Node2vec = Embedding_Node2vec.sort_values(\u001b[32m0\u001b[39m,ascending=\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;66;03m# 建立序号排序\u001b[39;00m\n\u001b[32m      5\u001b[39m Embedding_Node2vec.reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m) \n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m    935\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m    936\u001b[39m     dialect,\n\u001b[32m    937\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m    944\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m    945\u001b[39m )\n\u001b[32m    946\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m--> \u001b[39m\u001b[32m948\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    608\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    610\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m611\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    613\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    614\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1445\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1447\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1448\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1703\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1704\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1705\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1706\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1707\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1708\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1709\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1710\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1711\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1712\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1713\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1714\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1715\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1716\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\common.py:863\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    858\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    859\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    860\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    861\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    862\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m863\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    864\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    865\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    866\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    867\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    870\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    871\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    872\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'casestudy/data/Embedding_grarep.txt'"
     ]
    }
   ],
   "source": [
    "# 导入节点的Embedding_DeepWalk\n",
    "E_filename = 'casestudy/data/Embedding_grarep.txt'\n",
    "Embedding_Node2vec = pd.read_csv(E_filename,sep=' ',header=None)\n",
    "Embedding_Node2vec = Embedding_Node2vec.sort_values(0,ascending=True)# 建立序号排序\n",
    "Embedding_Node2vec.reset_index(drop=True, inplace=True) \n",
    "Embedding_Node2vec = Embedding_Node2vec.iloc[:,1:]\n",
    "Embedding_Node2vec[:10]\n",
    "print(len(Embedding_Node2vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 生成负样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NegativeGenerate(LncDisease, AllRNA, AllDisease, num):\n",
    "    # 负样本为全部的disease-rna（328*881）中随机抽取，未在内LncDisease即为负样本\n",
    "    import random\n",
    "    NegativeSample = []\n",
    "    counterN = 0\n",
    "    while counterN < len(num):  # 随机选出一个疾病rna对\n",
    "        counterR = random.randint(0, len(AllRNA) - 1)\n",
    "        counterD = random.randint(0, len(AllDisease) - 1)\n",
    "        DiseaseAndRnaPair = []\n",
    "        DiseaseAndRnaPair.append(AllRNA[counterR])\n",
    "        DiseaseAndRnaPair.append(AllDisease[counterD])\n",
    "        flag1 = 0\n",
    "        counter = 0\n",
    "        while counter < len(num):\n",
    "            if DiseaseAndRnaPair == LncDisease[counter]:\n",
    "                flag1 = 1\n",
    "                break\n",
    "            counter = counter + 1\n",
    "        if flag1 == 1:\n",
    "            continue\n",
    "        flag2 = 0\n",
    "        counter1 = 0\n",
    "        while counter1 < len(NegativeSample):  # 在已选的负样本中没有，防止重复\n",
    "            if DiseaseAndRnaPair == NegativeSample[counter1]:\n",
    "                flag2 = 1\n",
    "                break\n",
    "            counter1 = counter1 + 1\n",
    "        if flag2 == 1:\n",
    "            continue\n",
    "        if (flag1 == 0 & flag2 == 0):\n",
    "            NamePair = []  # 生成对\n",
    "            NamePair.append(AllRNA[counterR])\n",
    "            NamePair.append(AllDisease[counterD])\n",
    "            NegativeSample.append(NamePair)\n",
    "            counterN = counterN + 1\n",
    "    return NegativeSample\n",
    "Dr = pd.read_csv('data/drug_name.csv',header=0,names=['id','name'])\n",
    "Pr = pd.read_csv('data/protein_name.csv',header=0,names=['id','name'])\n",
    "alldata = DTIs.append(Case_data) # 添加了测试集中关系对，保证所生产的负样本不包含测试集\n",
    "NegativeSample = NegativeGenerate(alldata.values.tolist(),Dr['id'].values.tolist(),Pr['id'].values.tolist(),DTIs)\n",
    "NegativeSample = pd.DataFrame(NegativeSample)\n",
    "NegativeSample.to_csv('casestudy/data/NegativeSample.csv', header=None,index=False)\n",
    "NegativeSample.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vec = []\n",
    "Negative = pd.read_csv('casestudy/data/NegativeSample.csv',header=None)\n",
    "Negative[2] = Negative.apply(lambda x: 0 if x[0] < 0 else 0, axis=1)\n",
    "DTIs[2] = DTIs.apply(lambda x: 1 if x[0] < 0 else 1, axis=1)\n",
    "result = DTIs.append(Negative)\n",
    "labels = result[2]\n",
    "train_data = result[[0,1]]\n",
    "for i,j in np.array(train_data):\n",
    "    data_vec.append(np.hstack([np.hstack([np.array(GCN_data.iloc[i]),np.array(Embedding_Node2vec.iloc[i])]),np.hstack([np.array(GCN_data.iloc[j]),np.array(Embedding_Node2vec.iloc[j])])]))\n",
    "del Negative, train_data\n",
    "np.array(data_vec).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "case_RandomF = RandomForestClassifier(n_jobs=-1)# 选择最优的K=3传入模型\n",
    "print('开始训练')#训练模型L\n",
    "case_RandomF.fit(np.array(data_vec), np.array(labels))\n",
    "# 保存模型\n",
    "joblib.dump(case_RandomF,'casestudy/XGB.pkl')\n",
    "print('保存完毕')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据向量化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 导入test数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "case_data = pd.read_csv('casestudy/data/Casestudy_Num_all.csv',header=None)\n",
    "case_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "Case_vectort = []\n",
    "for i,j in np.array(case_data):#case_data\n",
    "    Case_vectort.append(np.hstack([np.hstack([np.array(GCN_data.iloc[i]),np.array(Embedding_Node2vec.iloc[i])]),np.hstack([np.array(GCN_data.iloc[j]),np.array(Embedding_Node2vec.iloc[j])])]))\n",
    "np.array(Case_vectort).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "model = joblib.load('casestudy/XGB.pkl')\n",
    "y_score_GBDT = model.predict_proba(np.array(Case_vectort))\n",
    "print('预测完毕！')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score_GBDT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID 转 Name\n",
    "import pandas as pd\n",
    "drug_name = pd.read_csv('data/drug_name.csv')\n",
    "drug_name = drug_name.rename(columns={'Unnamed: 0': 'DrugID'})\n",
    "drug_name.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_name = pd.read_csv('data/protein_name.csv')\n",
    "protein_name = protein_name.rename(columns={'Unnamed: 0': 'PrID'})\n",
    "protein_name.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = ['DrugID','PrID']\n",
    "case_data.columns = col_name\n",
    "case_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = pd.merge(case_data,protein_name,how='left',on='PrID')\n",
    "dd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd2 = pd.merge(dd,drug_name,how='left',on='DrugID')\n",
    "dd2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "drug = pd.read_csv('casestudy/data/drug.csv')\n",
    "drug.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd2['prob'] = y_score_GBDT[:,1]\n",
    "dd2[['drug','protein','prob']].to_csv('casestudy/results/CaseStudy_Prob_all.csv', index = False)\n",
    "print(\"保存完毕！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 匹配蛋白质命名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dd = pd.read_csv('casestudy/results/CaseStudy_Prob_all.csv')\n",
    "dd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('casestudy/data/uniprot-yourlist.xlsx')\n",
    "df = df.rename(columns={'yourlist:M20210116A94466D2655679D1FD8953E075198DA82FDBA03': 'protein'})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = pd.merge(dd,df,how='left',on='protein')\n",
    "ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf[['drug','protein','Entry name','Gene names','Protein names','prob']].to_csv('casestudy/results/NewCaseStudy_Prob_all.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
