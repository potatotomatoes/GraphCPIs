{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.007599</td>\n",
       "      <td>-0.007655</td>\n",
       "      <td>-0.003703</td>\n",
       "      <td>-0.007203</td>\n",
       "      <td>0.002032</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.005779</td>\n",
       "      <td>-0.008866</td>\n",
       "      <td>-0.00496</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005631</td>\n",
       "      <td>0.002488</td>\n",
       "      <td>-0.013618</td>\n",
       "      <td>-0.008738</td>\n",
       "      <td>0.007777</td>\n",
       "      <td>0.005095</td>\n",
       "      <td>0.00378</td>\n",
       "      <td>-0.015584</td>\n",
       "      <td>-0.005586</td>\n",
       "      <td>0.004156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.007599</td>\n",
       "      <td>-0.007655</td>\n",
       "      <td>-0.003703</td>\n",
       "      <td>-0.007203</td>\n",
       "      <td>0.002032</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.005779</td>\n",
       "      <td>-0.008866</td>\n",
       "      <td>-0.00496</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005631</td>\n",
       "      <td>0.002488</td>\n",
       "      <td>-0.013618</td>\n",
       "      <td>-0.008738</td>\n",
       "      <td>0.007777</td>\n",
       "      <td>0.005095</td>\n",
       "      <td>0.00378</td>\n",
       "      <td>-0.015584</td>\n",
       "      <td>-0.005586</td>\n",
       "      <td>0.004156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.007599</td>\n",
       "      <td>-0.007655</td>\n",
       "      <td>-0.003703</td>\n",
       "      <td>-0.007203</td>\n",
       "      <td>0.002032</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.005779</td>\n",
       "      <td>-0.008866</td>\n",
       "      <td>-0.00496</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005631</td>\n",
       "      <td>0.002488</td>\n",
       "      <td>-0.013618</td>\n",
       "      <td>-0.008738</td>\n",
       "      <td>0.007777</td>\n",
       "      <td>0.005095</td>\n",
       "      <td>0.00378</td>\n",
       "      <td>-0.015584</td>\n",
       "      <td>-0.005586</td>\n",
       "      <td>0.004156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.007599</td>\n",
       "      <td>-0.007655</td>\n",
       "      <td>-0.003703</td>\n",
       "      <td>-0.007203</td>\n",
       "      <td>0.002032</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.005779</td>\n",
       "      <td>-0.008866</td>\n",
       "      <td>-0.00496</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005631</td>\n",
       "      <td>0.002488</td>\n",
       "      <td>-0.013618</td>\n",
       "      <td>-0.008738</td>\n",
       "      <td>0.007777</td>\n",
       "      <td>0.005095</td>\n",
       "      <td>0.00378</td>\n",
       "      <td>-0.015584</td>\n",
       "      <td>-0.005586</td>\n",
       "      <td>0.004156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.180584</td>\n",
       "      <td>0.526513</td>\n",
       "      <td>0.793145</td>\n",
       "      <td>-0.245426</td>\n",
       "      <td>-0.220634</td>\n",
       "      <td>0.559357</td>\n",
       "      <td>1.059898</td>\n",
       "      <td>0.148331</td>\n",
       "      <td>-0.98174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003815</td>\n",
       "      <td>-0.553314</td>\n",
       "      <td>0.003378</td>\n",
       "      <td>0.335591</td>\n",
       "      <td>0.143528</td>\n",
       "      <td>-1.134055</td>\n",
       "      <td>0.62961</td>\n",
       "      <td>0.330191</td>\n",
       "      <td>0.377519</td>\n",
       "      <td>-0.798777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0         1         2         3         4         5         6         7   \\\n",
       "0   0 -0.007599 -0.007655 -0.003703 -0.007203  0.002032  0.006483  0.005779   \n",
       "1   1 -0.007599 -0.007655 -0.003703 -0.007203  0.002032  0.006483  0.005779   \n",
       "2   2 -0.007599 -0.007655 -0.003703 -0.007203  0.002032  0.006483  0.005779   \n",
       "3   3 -0.007599 -0.007655 -0.003703 -0.007203  0.002032  0.006483  0.005779   \n",
       "4   4  1.180584  0.526513  0.793145 -0.245426 -0.220634  0.559357  1.059898   \n",
       "\n",
       "         8        9   ...        55        56        57        58        59  \\\n",
       "0 -0.008866 -0.00496  ... -0.005631  0.002488 -0.013618 -0.008738  0.007777   \n",
       "1 -0.008866 -0.00496  ... -0.005631  0.002488 -0.013618 -0.008738  0.007777   \n",
       "2 -0.008866 -0.00496  ... -0.005631  0.002488 -0.013618 -0.008738  0.007777   \n",
       "3 -0.008866 -0.00496  ... -0.005631  0.002488 -0.013618 -0.008738  0.007777   \n",
       "4  0.148331 -0.98174  ...  0.003815 -0.553314  0.003378  0.335591  0.143528   \n",
       "\n",
       "         60       61        62        63        64  \n",
       "0  0.005095  0.00378 -0.015584 -0.005586  0.004156  \n",
       "1  0.005095  0.00378 -0.015584 -0.005586  0.004156  \n",
       "2  0.005095  0.00378 -0.015584 -0.005586  0.004156  \n",
       "3  0.005095  0.00378 -0.015584 -0.005586  0.004156  \n",
       "4 -1.134055  0.62961  0.330191  0.377519 -0.798777  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "node_features = pd.read_csv('data/Drug_Protein_Attribute.csv',header = None) \n",
    "Attributes = node_features.iloc[:,1:]\n",
    "node_features.head()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 比较不同属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import joblib\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评价指标\n",
    "def MyConfusionMatrix(y_real,y_predict): \n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    CM = confusion_matrix(y_real, y_predict)\n",
    "    print(CM)\n",
    "    CM = CM.tolist()\n",
    "    TN = CM[0][0]\n",
    "    FP = CM[0][1]\n",
    "    FN = CM[1][0]\n",
    "    TP = CM[1][1]\n",
    "    print('TN:%d, FP:%d, FN:%d, TP:%d' % (TN, FP, FN, TP))\n",
    "    Acc = (TN + TP) / (TN + TP + FN + FP)\n",
    "    Sen = TP / (TP + FN)\n",
    "    Spec = TN / (TN + FP)\n",
    "    Prec = TP / (TP + FP)\n",
    "    MCC = (TP * TN - FP * FN) / math.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n",
    "    # 分母可能出现0，需要讨论待续\n",
    "    print('Acc:', round(Acc, 4))\n",
    "    print('Sen:', round(Sen, 4))\n",
    "    print('Spec:', round(Spec, 4))\n",
    "    print('Prec:', round(Prec, 4))\n",
    "    print('MCC:', round(MCC, 4))\n",
    "    Result = []\n",
    "    Result.append(round(Acc, 4))\n",
    "    Result.append(round(Sen, 4))\n",
    "    Result.append(round(Spec, 4))\n",
    "    Result.append(round(Prec, 4))\n",
    "    Result.append(round(MCC, 4))\n",
    "    return Result\n",
    "\n",
    "def MyAverage(matrix):\n",
    "    SumAcc = 0\n",
    "    SumSen = 0\n",
    "    SumSpec = 0\n",
    "    SumPrec = 0\n",
    "    SumMcc = 0\n",
    "    counter = 0\n",
    "    while counter < len(matrix):\n",
    "        SumAcc = SumAcc + matrix[counter][0]\n",
    "        SumSen = SumSen + matrix[counter][1]\n",
    "        SumSpec = SumSpec + matrix[counter][2]\n",
    "        SumPrec = SumPrec + matrix[counter][3]\n",
    "        SumMcc = SumMcc + matrix[counter][4]\n",
    "        counter = counter + 1\n",
    "    print('AverageAcc:',SumAcc / len(matrix))\n",
    "    print('AverageSen:', SumSen / len(matrix))\n",
    "    print('AverageSpec:', SumSpec / len(matrix))\n",
    "    print('AveragePrec:', SumPrec / len(matrix))\n",
    "    print('AverageMcc:', SumMcc / len(matrix))\n",
    "    return\n",
    "\n",
    "def MyStd(result):\n",
    "    import numpy as np\n",
    "    NewMatrix = []\n",
    "    counter = 0\n",
    "    while counter < len(result[0]):\n",
    "        row = []\n",
    "        NewMatrix.append(row)\n",
    "        counter = counter + 1\n",
    "    counter = 0\n",
    "    while counter < len(result):\n",
    "        counter1 = 0\n",
    "        while counter1 < len(result[counter]):\n",
    "            NewMatrix[counter1].append(result[counter][counter1])\n",
    "            counter1 = counter1 + 1\n",
    "        counter = counter + 1\n",
    "    StdList = []\n",
    "    MeanList = []\n",
    "    counter = 0\n",
    "    while counter < len(NewMatrix):\n",
    "        # std\n",
    "        arr_std = np.std(NewMatrix[counter], ddof=1)\n",
    "        StdList.append(arr_std)\n",
    "        # mean\n",
    "        arr_mean = np.mean(NewMatrix[counter])\n",
    "        MeanList.append(arr_mean)\n",
    "        counter = counter + 1\n",
    "    result.append(MeanList)\n",
    "    result.append(StdList)\n",
    "    # 换算成百分比制\n",
    "    counter = 0\n",
    "    while counter < len(result):\n",
    "        counter1 = 0\n",
    "        while counter1 < len(result[counter]):\n",
    "            result[counter][counter1] = round(result[counter][counter1] * 100, 2)\n",
    "            counter1 = counter1 + 1\n",
    "        counter = counter + 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 只有Attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/deven/Desktop/CPIs/data/NegativeSample.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m creat_var = \u001b[38;5;28mlocals\u001b[39m() \u001b[38;5;66;03m# 利用locals()创建变量\u001b[39;00m\n\u001b[32m      5\u001b[39m creat_var = \u001b[38;5;28mlocals\u001b[39m() \u001b[38;5;66;03m# 利用locals()创建变量\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m Negative = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mC:/Users/deven/Desktop/CPIs/data/NegativeSample.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m Nindex = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mC:/Users/deven/Desktop/CPIs/data/NewRandomList.csv\u001b[39m\u001b[33m'\u001b[39m,header=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m      8\u001b[39m Negative[\u001b[32m2\u001b[39m] = Negative.apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[32m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x[\u001b[32m0\u001b[39m] < \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m, axis=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m    935\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m    936\u001b[39m     dialect,\n\u001b[32m    937\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m    944\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m    945\u001b[39m )\n\u001b[32m    946\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m--> \u001b[39m\u001b[32m948\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    608\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    610\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m611\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    613\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    614\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1445\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1447\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1448\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1703\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1704\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1705\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1706\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1707\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1708\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1709\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1710\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1711\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1712\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1713\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1714\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1715\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1716\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\common.py:863\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    858\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    859\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    860\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    861\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    862\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m863\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    864\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    865\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    866\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    867\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    870\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    871\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    872\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'C:/Users/deven/Desktop/CPIs/data/NegativeSample.csv'"
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "creat_var = locals() # 利用locals()创建变量\n",
    "creat_var = locals() # 利用locals()创建变量\n",
    "Negative = pd.read_csv('data/NegativeSample.csv',header=None)\n",
    "Nindex = pd.read_csv('data/NewRandomList.csv',header=None)\n",
    "Negative[2] = Negative.apply(lambda x: 0 if x[0] < 0 else 0, axis=1)\n",
    "for i in range(5):\n",
    "    data_train_feature, data_test_feature = [], []\n",
    "#     Embedding_GCN = pd.read_csv('./data/Emdebding_GCN'+str(i)+'.csv',header=None)\n",
    "#     Embedding_Node2vec = pd.read_csv('./data/Embedding_Node2vec'+str(i)+'.txt', sep=' ',header=None)\n",
    "#     Embedding_Node2vec = Embedding_Node2vec.sort_values(0,ascending=True)# 建立序号排序\n",
    "#     Embedding_Node2vec.reset_index(drop=True, inplace=True) \n",
    "#     Embedding_Node2vec = Embedding_Node2vec.iloc[:,1:]\n",
    "    train_data = pd.read_csv('data/DTIs_train'+str(i)+'.csv',header=None)\n",
    "    train_data[2] = train_data.apply(lambda x: 1 if x[0] < 0 else 1, axis=1)\n",
    "    kk = []\n",
    "    for j in range(5):\n",
    "        if j !=i:\n",
    "            kk.append(j)\n",
    "    index = np.hstack([np.array(Nindex)[kk[0]],np.array(Nindex)[kk[1]],np.array(Nindex)[kk[2]],np.array(Nindex)[kk[3]]])\n",
    "    result = train_data.append(pd.DataFrame(np.array(Negative)[index]))    \n",
    "    labels_train = result[2]# np.hstack([np.array(Embedding_GCN)[result.iloc[r,0]],np.array(Embedding_Node2vec)[result.iloc[r,0]]])\n",
    "    for r in range(len(result)):# np.hstack([np.array(Embedding_GCN)[result.iloc[r,1]],np.array(Embedding_Node2vec)[result.iloc[r,1]]])\n",
    "        data_train_feature.append(np.hstack([np.array(Attributes)[result.iloc[r,0]],\n",
    "                                             np.array(Attributes)[result.iloc[r,1]]]))\n",
    "    creat_var['A_data_train'+str(i)] = data_train_feature\n",
    "    creat_var['A_labels_train'+str(i)] = labels_train\n",
    "    print(len(labels_train))\n",
    "    del labels_train, result, data_train_feature, r\n",
    "    test_data = pd.read_csv('data/DTIs_test'+str(i)+'.csv',header=None)\n",
    "    test_data[2] = test_data.apply(lambda x: 1 if x[0] < 0 else 1, axis=1)\n",
    "    result = test_data.append(pd.DataFrame(np.array(Negative)[np.array(Nindex)[i]]))    \n",
    "    labels_test = result[2]# np.hstack([np.array(Embedding_GCN)[result.iloc[x,0]],np.array(Embedding_Node2vec)[result.iloc[x,0]]])\n",
    "    for x in range(len(result)):#np.hstack([np.array(Embedding_GCN)[result.iloc[x,1]],np.array(Embedding_Node2vec)[result.iloc[x,1]]])\n",
    "        data_test_feature.append(np.hstack([np.array(Attributes)[result.iloc[x,0]],\n",
    "                                            np.array(Attributes)[result.iloc[x,1]]]))\n",
    "    creat_var['A_data_test'+str(i)] = data_test_feature\n",
    "    creat_var['A_labels_test'+str(i)] = labels_test\n",
    "    print(len(labels_test))\n",
    "    del train_data, test_data, labels_test, result, data_test_feature, x   \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_data_train = [A_data_train0,A_data_train1,A_data_train2,A_data_train3,A_data_train4]\n",
    "A_data_test = [A_data_test0,A_data_test1,A_data_test2,A_data_test3,A_data_test4]\n",
    "A_labels_train = [A_labels_train0,A_labels_train1,A_labels_train2,A_labels_train3,A_labels_train4]\n",
    "A_labels_test = [A_labels_test0,A_labels_test1,A_labels_test2,A_labels_test3,A_labels_test4]\n",
    "print(len(A_data_train0))\n",
    "print(np.array(A_data_train0).shape)\n",
    "print(len(A_labels_test0))\n",
    "print(np.array(A_labels_test0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import joblib\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# 画ROC曲线，计算AUC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from scipy import interp\n",
    "import time\n",
    "\n",
    "now = time.strftime(\"%Y-%m-%d-%H_%M_%S\",time.localtime(time.time()))\n",
    "\n",
    "# print(\"迭代寻找最优参数\")\n",
    "# k_range = [301, 401, 501, 601, 701, 801, 901, 999]\n",
    "# cv_scores = [] #用来放每个模型的结果值\n",
    "# for n in k_range:\n",
    "#     print('n_estimators: %d '%(n))\n",
    "#     RandomF = RandomForestClassifier(n_estimators=n)   #knn模型，这里一个超参数可以做预测，当多个超参数时需要使用另一种方法GridSearchCV\n",
    "#     scores = cross_val_score(RandomF,data_train0, labels_train0,\n",
    "#                              cv=5,\n",
    "#                              scoring='roc_auc', \n",
    "#                              n_jobs=-1)  #cv：选择每次测试折数  accuracy：评价指标是准确度,可以省略使用默认值，具体使用参考下面。\n",
    "#     cv_scores.append(scores.mean())\n",
    "# print(\"best_n_neighbors is：\", k_range[cv_scores.index(max(cv_scores))])\n",
    "\n",
    "print(\"进行5折交叉验证\")\n",
    "tprs=[]\n",
    "aucs=[]\n",
    "mean_fpr=np.linspace(0,1,1000)\n",
    "# 定义i用于绘制每次训练的ROC曲线\n",
    "\n",
    "# ROC曲线颜色\n",
    "colorlist = ['red', 'gold', 'purple', 'green', 'blue', 'black']\n",
    "# 保存评价指标\n",
    "AllResult = []\n",
    "\n",
    "#data为数据集,利用KF.split划分训练集和测试集\n",
    "for i in range(5):\n",
    "    #建立模型，并对训练集进行测试，求出预测得分\n",
    "    #划分训练集和测试集\n",
    "    print('正在划分训练集和测试集...')\n",
    "    X_train,X_test = A_data_train[i],A_data_test[i]\n",
    "    Y_train,Y_test = np.array(A_labels_train[i]),np.array(A_labels_test[i])\n",
    "    print('划分完毕！')\n",
    "    #建立模型 # n_estimators=k_range[cv_scores.index(max(cv_scores))]\n",
    "    best_XGB = XGBClassifier(learning_rate=0.15,max_depth=500,n_estimators=500)\n",
    "    print('开始训练')\n",
    "    #训练模型\n",
    "    best_XGB.fit(np.array(X_train), np.array(Y_train))\n",
    "    # 保存模型\n",
    "    joblib.dump(best_XGB,'compare/model/'+'XGB_A_'+str(i)+'.pkl')\n",
    "    #利用model.predict获取测试集的预测值\n",
    "    y_score0 = best_XGB.predict(np.array(X_test))\n",
    "    y_score_XGB = best_XGB.predict_proba(np.array(X_test))\n",
    "    # 输出混淆矩阵\n",
    "    print(confusion_matrix(Y_test, y_score0)) # , labels=[1,0]\n",
    "    \n",
    "    dd = np.vstack([Y_test, y_score_XGB[:,1]]).T\n",
    "    XGB_data = pd.DataFrame(dd)\n",
    "    XGB_data.to_csv('/compare/predict/' + 'XGB_A_'+ str(i)+ 'Prob.csv', header = False, index = False)\n",
    "    \n",
    "    #计算fpr(假阳性率),tpr(真阳性率),thresholds(阈值)[绘制ROC曲线要用到这几个值]\n",
    "    fpr,tpr,thresholds=roc_curve(Y_test,y_score_XGB[:,1])\n",
    "    #interp:插值 把结果添加到tprs列表中 \n",
    "    tprs.append(interp(mean_fpr,fpr,tpr))\n",
    "    tprs[-1][0]=0.0\n",
    "    #计算auc\n",
    "    roc_auc=auc(fpr,tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    #画图，只需要plt.plot(fpr,tpr),变量roc_auc只是记录auc的值，通过auc()函数计算出来\n",
    "    plt.plot(fpr,tpr,lw=1.5,alpha=0.8,color=colorlist[i],\n",
    "             label='ROC fold %d(AUC=%0.4f)'% (i,roc_auc))\n",
    "    print(\"---------------------------------------------\\n\")\n",
    "    print(\"fold = \", i)\n",
    "    print(\"---------------------------------------------\\n\")\n",
    "    Result = MyConfusionMatrix(Y_test, y_score0)\n",
    "    AllResult.append(Result)\n",
    "    AllResult[i].append(roc_auc)\n",
    "    i +=1\n",
    "\n",
    "# 保存各种评价指标\n",
    "MyAverage(AllResult)\n",
    "# AllResult\n",
    "# print('AllResult', AllResult)\n",
    "MyNew = MyStd(AllResult)\n",
    "# StorFile(MyNew, '五折的评价指标.csv')\n",
    "df = pd.DataFrame(data = MyNew)\n",
    "df.to_csv('compare/evaluate/XGB_A_5-fold.csv', encoding='utf-8',header=None,index=False)\n",
    "\n",
    "#画对角线\n",
    "plt.plot([0,1],[0,1],linestyle='--',lw=2,color='rosybrown',alpha=0.8)\n",
    "mean_tpr=np.mean(tprs,axis=0)\n",
    "mean_tpr[-1]=1.0\n",
    "mean_auc=auc(mean_fpr,mean_tpr)#计算平均AUC值\n",
    "std_auc=np.std(tprs,axis=0)\n",
    "plt.plot(mean_fpr,mean_tpr,color=colorlist[i],label=r'Mean ROC (AUC=%0.4f)'%mean_auc,lw=2,alpha=1)\n",
    "std_tpr=np.std(tprs,axis=0)\n",
    "plt.xlim([-0.05,1.05])\n",
    "plt.ylim([-0.05,1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='best')\n",
    "plt.savefig('compare/image/'+ now + 'XGB_A_ROC.svg')\n",
    "plt.show()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del A_data_train, A_data_test, A_labels_train, A_labels_test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 只有GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "creat_var = locals() # 利用locals()创建变量\n",
    "creat_var = locals() # 利用locals()创建变量\n",
    "Negative = pd.read_csv('C:/Users/deven/Desktop/CPIs/data/NegativeSample.csv',header=None)\n",
    "Nindex = pd.read_csv('C:/Users/deven/Desktop/CPIs/data/NewRandomList.csv',header=None)\n",
    "Negative[2] = Negative.apply(lambda x: 0 if x[0] < 0 else 0, axis=1)\n",
    "for i in range(5):\n",
    "    data_train_feature, data_test_feature = [], []\n",
    "    Embedding_GCN = pd.read_csv('C:/Users/deven/Desktop/CPIs/data/Emdebding_GCN_1'+str(i)+'.csv',header=None)\n",
    "    train_data = pd.read_csv('C:/Users/deven/Desktop/CPIs/data/DTIs_train'+str(i)+'.csv',header=None)\n",
    "    train_data[2] = train_data.apply(lambda x: 1 if x[0] < 0 else 1, axis=1)\n",
    "    kk = []\n",
    "    for j in range(5):\n",
    "        if j !=i:\n",
    "            kk.append(j)\n",
    "    index = np.hstack([np.array(Nindex)[kk[0]],np.array(Nindex)[kk[1]],np.array(Nindex)[kk[2]],np.array(Nindex)[kk[3]]])\n",
    "    result = train_data.append(pd.DataFrame(np.array(Negative)[index]))    \n",
    "    labels_train = result[2]# np.hstack([np.array(Embedding_GCN)[result.iloc[r,0]],np.array(Embedding_Node2vec)[result.iloc[r,0]]])\n",
    "    for r in range(len(result)):# np.hstack([np.array(Embedding_GCN)[result.iloc[r,1]],np.array(Embedding_Node2vec)[result.iloc[r,1]]])\n",
    "        data_train_feature.append(np.hstack([np.array(Embedding_GCN)[result.iloc[r,0]],\n",
    "                                             np.array(Embedding_GCN)[result.iloc[r,1]]]))\n",
    "    creat_var['G_data_train'+str(i)] = data_train_feature\n",
    "    creat_var['G_labels_train'+str(i)] = labels_train\n",
    "    print(len(labels_train))\n",
    "    del labels_train, result, data_train_feature, r\n",
    "    test_data = pd.read_csv('C:/Users/deven/Desktop/CPIs/data/DTIs_test'+str(i)+'.csv',header=None)\n",
    "    test_data[2] = test_data.apply(lambda x: 1 if x[0] < 0 else 1, axis=1)\n",
    "    result = test_data.append(pd.DataFrame(np.array(Negative)[np.array(Nindex)[i]]))    \n",
    "    labels_test = result[2]# np.hstack([np.array(Embedding_GCN)[result.iloc[x,0]],np.array(Embedding_Node2vec)[result.iloc[x,0]]])\n",
    "    for x in range(len(result)):#np.hstack([np.array(Embedding_GCN)[result.iloc[x,1]],np.array(Embedding_Node2vec)[result.iloc[x,1]]])\n",
    "        data_test_feature.append(np.hstack([np.array(Embedding_GCN)[result.iloc[x,0]],\n",
    "                                            np.array(Embedding_GCN)[result.iloc[x,1]]]))\n",
    "    creat_var['G_data_test'+str(i)] = data_test_feature\n",
    "    creat_var['G_labels_test'+str(i)] = labels_test\n",
    "    print(len(labels_test))\n",
    "    del train_data, test_data, labels_test, result, data_test_feature, x   \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_data_train = [G_data_train0,G_data_train1,G_data_train2,G_data_train3,G_data_train4]\n",
    "G_data_test = [G_data_test0,G_data_test1,G_data_test2,G_data_test3,G_data_test4]\n",
    "G_labels_train = [G_labels_train0,G_labels_train1,G_labels_train2,G_labels_train3,G_labels_train4]\n",
    "G_labels_test = [G_labels_test0,G_labels_test1,G_labels_test2,G_labels_test3,G_labels_test4]\n",
    "print(len(G_data_train0))\n",
    "print(np.array(G_data_train0).shape)\n",
    "print(len(G_labels_test0))\n",
    "print(np.array(G_labels_test0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import joblib\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# 画ROC曲线，计算AUC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from scipy import interp\n",
    "import time\n",
    "\n",
    "now = time.strftime(\"%Y-%m-%d-%H_%M_%S\",time.localtime(time.time()))\n",
    "print(\"进行5折交叉验证\")\n",
    "tprs=[]\n",
    "aucs=[]\n",
    "mean_fpr=np.linspace(0,1,1000)\n",
    "# 定义i用于绘制每次训练的ROC曲线\n",
    "\n",
    "# ROC曲线颜色\n",
    "colorlist = ['red', 'gold', 'purple', 'green', 'blue', 'black']\n",
    "# 保存评价指标\n",
    "AllResult = []\n",
    "\n",
    "#data为数据集,利用KF.split划分训练集和测试集\n",
    "for i in range(5):\n",
    "    #建立模型，并对训练集进行测试，求出预测得分\n",
    "    #划分训练集和测试集\n",
    "    print('正在划分训练集和测试集...')\n",
    "    X_train,X_test = G_data_train[i],G_data_test[i]\n",
    "    Y_train,Y_test = np.array(G_labels_train[i]),np.array(G_labels_test[i])\n",
    "    print('划分完毕！')\n",
    "    #建立模型 # n_estimators=k_range[cv_scores.index(max(cv_scores))]\n",
    "    best_XGB = XGBClassifier(learning_rate=0.15,max_depth=500,n_estimators=500)\n",
    "    print('开始训练')\n",
    "    #训练模型\n",
    "    best_XGB.fit(np.array(X_train), np.array(Y_train))\n",
    "    # 保存模型\n",
    "    joblib.dump(best_XGB,'C:/Users/deven/Desktop/CPIs/compare/model/'+'XGB_G_'+str(i)+'.pkl')\n",
    "    #利用model.predict获取测试集的预测值\n",
    "    y_score0 = best_XGB.predict(np.array(X_test))\n",
    "    y_score_XGB = best_XGB.predict_proba(np.array(X_test))\n",
    "    # 输出混淆矩阵\n",
    "    print(confusion_matrix(Y_test, y_score0)) # , labels=[1,0]\n",
    "    \n",
    "    dd = np.vstack([Y_test, y_score_XGB[:,1]]).T\n",
    "    XGB_data = pd.DataFrame(dd)\n",
    "    XGB_data.to_csv('C:/Users/deven/Desktop/CPIs/compare/predict/' + 'XGB_G_'+ str(i)+ 'Prob.csv', header = False, index = False)\n",
    "    \n",
    "    #计算fpr(假阳性率),tpr(真阳性率),thresholds(阈值)[绘制ROC曲线要用到这几个值]\n",
    "    fpr,tpr,thresholds=roc_curve(Y_test,y_score_XGB[:,1])\n",
    "    #interp:插值 把结果添加到tprs列表中 \n",
    "    tprs.append(interp(mean_fpr,fpr,tpr))\n",
    "    tprs[-1][0]=0.0\n",
    "    #计算auc\n",
    "    roc_auc=auc(fpr,tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    #画图，只需要plt.plot(fpr,tpr),变量roc_auc只是记录auc的值，通过auc()函数计算出来\n",
    "    plt.plot(fpr,tpr,lw=1.5,alpha=0.8,color=colorlist[i],\n",
    "             label='ROC fold %d(AUC=%0.4f)'% (i,roc_auc))\n",
    "    print(\"---------------------------------------------\\n\")\n",
    "    print(\"fold = \", i)\n",
    "    print(\"---------------------------------------------\\n\")\n",
    "    Result = MyConfusionMatrix(Y_test, y_score0)\n",
    "    AllResult.append(Result)\n",
    "    AllResult[i].append(roc_auc)\n",
    "    i +=1\n",
    "\n",
    "# 保存各种评价指标\n",
    "MyAverage(AllResult)\n",
    "# AllResult\n",
    "# print('AllResult', AllResult)\n",
    "MyNew = MyStd(AllResult)\n",
    "# StorFile(MyNew, '五折的评价指标.csv')\n",
    "df = pd.DataFrame(data = MyNew)\n",
    "df.to_csv('C:/Users/deven/Desktop/CPIs/compare/evaluate/XGB_G_5-fold.csv', encoding='utf-8',header=None,index=False)\n",
    "\n",
    "#画对角线\n",
    "plt.plot([0,1],[0,1],linestyle='--',lw=2,color='rosybrown',alpha=0.8)\n",
    "mean_tpr=np.mean(tprs,axis=0)\n",
    "mean_tpr[-1]=1.0\n",
    "mean_auc=auc(mean_fpr,mean_tpr)#计算平均AUC值\n",
    "std_auc=np.std(tprs,axis=0)\n",
    "plt.plot(mean_fpr,mean_tpr,color=colorlist[i],label=r'Mean ROC (AUC=%0.4f)'%mean_auc,lw=2,alpha=1)\n",
    "std_tpr=np.std(tprs,axis=0)\n",
    "plt.xlim([-0.05,1.05])\n",
    "plt.ylim([-0.05,1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='best')\n",
    "plt.savefig('C:/Users/deven/Desktop/CPIs/compare/image/'+ now + 'XGB_G_ROC.svg')\n",
    "plt.show()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del G_data_train, G_data_test, G_labels_train, G_labels_test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 只有Network Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = pd.DataFrame(np.random.randint(0,1,node_features.shape[0]))\n",
    "dd['index']=dd.index\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "creat_var = locals() # 利用locals()创建变量\n",
    "creat_var = locals() # 利用locals()创建变量\n",
    "Negative = pd.read_csv('C:/Users/deven/Desktop/CPIs/data/NegativeSample.csv',header=None)\n",
    "Nindex = pd.read_csv('C:/Users/deven/Desktop/CPIs/data/NewRandomList.csv',header=None)\n",
    "Negative[2] = Negative.apply(lambda x: 0 if x[0] < 0 else 0, axis=1)\n",
    "for i in range(5):\n",
    "    data_train_feature, data_test_feature = [], []\n",
    "    Embedding_grarep = pd.read_csv('C:/Users/deven/Desktop/CPIs/data/Embedding_grarep'+str(i)+'.txt', sep=' ',header=None, error_bad_lines=False)\n",
    "    Embedding_grarep = Embedding_grarep.sort_values(0,ascending=True)# 建立序号排序\n",
    "    Embedding_grarep.set_index(0, inplace=True)\n",
    "    Embedding_grarep['index'] = Embedding_grarep.index\n",
    "    Embedding = pd.merge(dd,Embedding_grarep,how='left',on='index')\n",
    "    Embedding = Embedding.fillna(int(0)).iloc[:,2:]\n",
    "    train_data = pd.read_csv('C:/Users/deven/Desktop/CPIs/data/DTIs_train'+str(i)+'.csv',header=None)\n",
    "    train_data[2] = train_data.apply(lambda x: 1 if x[0] < 0 else 1, axis=1)\n",
    "    kk = []\n",
    "    for j in range(5):\n",
    "        if j !=i:\n",
    "            kk.append(j)\n",
    "    index = np.hstack([np.array(Nindex)[kk[0]],np.array(Nindex)[kk[1]],np.array(Nindex)[kk[2]],np.array(Nindex)[kk[3]]])\n",
    "    result = train_data.append(pd.DataFrame(np.array(Negative)[index]))    \n",
    "    labels_train = result[2]\n",
    "    for r in range(len(result)):\n",
    "        data_train_feature.append(np.hstack([np.array(Embedding)[result.iloc[r,0]],\n",
    "                                            np.array(Embedding)[result.iloc[r,1]]]))\n",
    "    creat_var['E_data_train'+str(i)] = data_train_feature\n",
    "    creat_var['E_labels_train'+str(i)] = labels_train\n",
    "    print(len(labels_train))\n",
    "    del labels_train, result, data_train_feature, r\n",
    "    test_data = pd.read_csv('C:/Users/deven/Desktop/CPIs/data/DTIs_test'+str(i)+'.csv',header=None)\n",
    "    test_data[2] = test_data.apply(lambda x: 1 if x[0] < 0 else 1, axis=1)\n",
    "    result = test_data.append(pd.DataFrame(np.array(Negative)[np.array(Nindex)[i]]))    \n",
    "    labels_test = result[2]\n",
    "    for x in range(len(result)):\n",
    "        data_test_feature.append(np.hstack([np.array(Embedding)[result.iloc[x,0]],\n",
    "                                            np.array(Embedding)[result.iloc[x,1]]]))\n",
    "    creat_var['E_data_test'+str(i)] = data_test_feature\n",
    "    creat_var['E_labels_test'+str(i)] = labels_test\n",
    "    print(len(labels_test))\n",
    "    del train_data, test_data, labels_test, result, data_test_feature, x   \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_data_train = [E_data_train0,E_data_train1,E_data_train2,E_data_train3,E_data_train4]\n",
    "E_data_test = [E_data_test0,E_data_test1,E_data_test2,E_data_test3,E_data_test4]\n",
    "E_labels_train = [E_labels_train0,E_labels_train1,E_labels_train2,E_labels_train3,E_labels_train4]\n",
    "E_labels_test = [E_labels_test0,E_labels_test1,E_labels_test2,E_labels_test3,E_labels_test4]\n",
    "print(len(E_data_train0))\n",
    "print(np.array(E_data_train0).shape)\n",
    "print(len(E_labels_test0))\n",
    "print(np.array(E_labels_test0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import joblib\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# 画ROC曲线，计算AUC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from scipy import interp\n",
    "import time\n",
    "\n",
    "now = time.strftime(\"%Y-%m-%d-%H_%M_%S\",time.localtime(time.time()))\n",
    "\n",
    "\n",
    "print(\"进行5折交叉验证\")\n",
    "tprs=[]\n",
    "aucs=[]\n",
    "mean_fpr=np.linspace(0,1,1000)\n",
    "# 定义i用于绘制每次训练的ROC曲线\n",
    "\n",
    "# ROC曲线颜色\n",
    "colorlist = ['red', 'gold', 'purple', 'green', 'blue', 'black']\n",
    "# 保存评价指标\n",
    "AllResult = []\n",
    "\n",
    "#data为数据集,利用KF.split划分训练集和测试集\n",
    "for i in range(5):\n",
    "    #建立模型，并对训练集进行测试，求出预测得分\n",
    "    #划分训练集和测试集\n",
    "    print('正在划分训练集和测试集...')\n",
    "    X_train,X_test = E_data_train[i],E_data_test[i]\n",
    "    Y_train,Y_test = np.array(E_labels_train[i]),np.array(E_labels_test[i])\n",
    "    print('划分完毕！')\n",
    "    #建立模型 # n_estimators=k_range[cv_scores.index(max(cv_scores))]\n",
    "    best_XGB = XGBClassifier(learning_rate=0.15,max_depth=500,n_estimators=500)\n",
    "    print('开始训练')\n",
    "    #训练模型\n",
    "    best_XGB.fit(np.array(X_train), np.array(Y_train))\n",
    "    # 保存模型\n",
    "    joblib.dump(best_XGB,'C:/Users/deven/Desktop/CPIs/compare/model/'+'XGB_N_'+str(i)+'.pkl')\n",
    "    #利用model.predict获取测试集的预测值\n",
    "    y_score0 = best_XGB.predict(np.array(X_test))\n",
    "    y_score_XGB = best_XGB.predict_proba(np.array(X_test))\n",
    "    # 输出混淆矩阵\n",
    "    print(confusion_matrix(Y_test, y_score0)) # , labels=[1,0]\n",
    "    \n",
    "    dd = np.vstack([Y_test, y_score_XGB[:,1]]).T\n",
    "    XGB_data = pd.DataFrame(dd)\n",
    "    XGB_data.to_csv('C:/Users/deven/Desktop/CPIs/compare/predict/' + 'XGB_N_'+ str(i)+ 'Prob.csv', header = False, index = False)\n",
    "    \n",
    "    #计算fpr(假阳性率),tpr(真阳性率),thresholds(阈值)[绘制ROC曲线要用到这几个值]\n",
    "    fpr,tpr,thresholds=roc_curve(Y_test,y_score_XGB[:,1])\n",
    "    #interp:插值 把结果添加到tprs列表中 \n",
    "    tprs.append(interp(mean_fpr,fpr,tpr))\n",
    "    tprs[-1][0]=0.0\n",
    "    #计算auc\n",
    "    roc_auc=auc(fpr,tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    #画图，只需要plt.plot(fpr,tpr),变量roc_auc只是记录auc的值，通过auc()函数计算出来\n",
    "    plt.plot(fpr,tpr,lw=1.5,alpha=0.8,color=colorlist[i],\n",
    "             label='ROC fold %d(AUC=%0.4f)'% (i,roc_auc))\n",
    "    print(\"---------------------------------------------\\n\")\n",
    "    print(\"fold = \", i)\n",
    "    print(\"---------------------------------------------\\n\")\n",
    "    Result = MyConfusionMatrix(Y_test, y_score0)\n",
    "    AllResult.append(Result)\n",
    "    AllResult[i].append(roc_auc)\n",
    "    i +=1\n",
    "\n",
    "# 保存各种评价指标\n",
    "MyAverage(AllResult)\n",
    "# AllResult\n",
    "# print('AllResult', AllResult)\n",
    "MyNew = MyStd(AllResult)\n",
    "# StorFile(MyNew, '五折的评价指标.csv')\n",
    "df = pd.DataFrame(data = MyNew)\n",
    "df.to_csv('C:/Users/deven/Desktop/CPIs/compare/evaluate/XGB_N_5-fold.csv', encoding='utf-8',header=None,index=False)\n",
    "\n",
    "#画对角线\n",
    "plt.plot([0,1],[0,1],linestyle='--',lw=2,color='rosybrown',alpha=0.8)\n",
    "mean_tpr=np.mean(tprs,axis=0)\n",
    "mean_tpr[-1]=1.0\n",
    "mean_auc=auc(mean_fpr,mean_tpr)#计算平均AUC值\n",
    "std_auc=np.std(tprs,axis=0)\n",
    "plt.plot(mean_fpr,mean_tpr,color=colorlist[i],label=r'Mean ROC (AUC=%0.4f)'%mean_auc,lw=2,alpha=1)\n",
    "std_tpr=np.std(tprs,axis=0)\n",
    "plt.xlim([-0.05,1.05])\n",
    "plt.ylim([-0.05,1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='best')\n",
    "plt.savefig('C:/Users/deven/Desktop/CPIs/compare/image/'+ now + 'XGB_N_ROC.svg')\n",
    "plt.show()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del E_data_train, E_data_test, E_labels_train, E_labels_test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attribute + Network Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   画ROC曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画ROC曲线，计算AUC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from scipy import interp\n",
    "import time\n",
    "# 画ROC曲线\n",
    "colorlist = ['red', 'gold', 'purple', 'limegreen', 'darkblue', 'black']\n",
    "\n",
    "for i in range(1):\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    mean_fpr = np.linspace(0, 1, 1000)\n",
    "    for j in range(5):\n",
    "        # 读取文件\n",
    "        RAPNameProb = 'C:/Users/deven/Desktop/CPIs/predict/XGB_' + str(j) + 'Prob.csv'\n",
    "        RealAndPredictionProb = pd.read_csv(RAPNameProb, header=None)\n",
    "\n",
    "        Real = RealAndPredictionProb[0]\n",
    "        PredictionProb = RealAndPredictionProb[1]\n",
    "\n",
    "        # 画图\n",
    "        fpr, tpr, thresholds = roc_curve(Real,PredictionProb)\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "    \n",
    "     # 画均值\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr) \n",
    "    mean_tpr=np.mean(tprs,axis=0)\n",
    "    mean_tpr[-1]=1.0\n",
    "    mean_auc=auc(mean_fpr,mean_tpr)#计算平均AUC值\n",
    "    plt.plot(mean_fpr,mean_tpr,color=colorlist[5],label=r'GraphCPIs(AUC=%0.4f)'%mean_auc,lw=1.5,alpha=1)\n",
    "    \n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    mean_fpr = np.linspace(0, 1, 1000)\n",
    "    for j in range(5):\n",
    "        # 读取文件\n",
    "        RAPNameProb =  'C:/Users/deven/Desktop/CPIs/compare/predict/XGB_G_' + str(j) + 'Prob.csv'\n",
    "        RealAndPredictionProb = pd.read_csv(RAPNameProb, header=None)\n",
    "\n",
    "        Real = RealAndPredictionProb[0]\n",
    "        PredictionProb = RealAndPredictionProb[1]\n",
    "\n",
    "        # 画图\n",
    "        fpr, tpr, thresholds = roc_curve(Real,PredictionProb)\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "\n",
    "     # 画均值\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr) \n",
    "    mean_tpr=np.mean(tprs,axis=0)\n",
    "    mean_tpr[-1]=1.0\n",
    "    mean_auc=auc(mean_fpr,mean_tpr)#计算平均AUC值\n",
    "    plt.plot(mean_fpr,mean_tpr,linestyle='-.',color=colorlist[3],label=r'GCN(AUC=%0.4f)'%mean_auc,lw=1.5,alpha=1)\n",
    "    \n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    mean_fpr = np.linspace(0, 1, 1000)\n",
    "    for j in range(5):\n",
    "        # 读取文件\n",
    "        RAPNameProb =  'C:/Users/deven/Desktop/CPIs/compare/predict/XGB_A_' + str(j) + 'Prob.csv'\n",
    "        RealAndPredictionProb = pd.read_csv(RAPNameProb, header=None)\n",
    "\n",
    "        Real = RealAndPredictionProb[0]\n",
    "        PredictionProb = RealAndPredictionProb[1]\n",
    "\n",
    "        # 画图\n",
    "        fpr, tpr, thresholds = roc_curve(Real,PredictionProb)\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "\n",
    "     # 画均值\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr) \n",
    "    mean_tpr=np.mean(tprs,axis=0)\n",
    "    mean_tpr[-1]=1.0\n",
    "    mean_auc=auc(mean_fpr,mean_tpr)#计算平均AUC值\n",
    "    plt.plot(mean_fpr,mean_tpr,linestyle='-',color=colorlist[4],label=r'FP+Seq(AUC=%0.4f)'%mean_auc,lw=1.5,alpha=1)\n",
    "    \n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    mean_fpr = np.linspace(0, 1, 1000)\n",
    "    for j in range(5):\n",
    "        # 读取文件\n",
    "        RAPNameProb =  'C:/Users/deven/Desktop/CPIs/compare/predict/XGB_N_' + str(j) + 'Prob.csv'\n",
    "        RealAndPredictionProb = pd.read_csv(RAPNameProb, header=None)\n",
    "\n",
    "        Real = RealAndPredictionProb[0]\n",
    "        PredictionProb = RealAndPredictionProb[1]\n",
    "\n",
    "        # 画图\n",
    "        fpr, tpr, thresholds = roc_curve(Real,PredictionProb)\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "\n",
    "     # 画均值\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr) \n",
    "    mean_tpr=np.mean(tprs,axis=0)\n",
    "    mean_tpr[-1]=1.0\n",
    "    mean_auc=auc(mean_fpr,mean_tpr)#计算平均AUC值\n",
    "    plt.plot(mean_fpr,mean_tpr,linestyle=':',color=colorlist[0],label=r'Grarep(AUC=%0.4f)'%mean_auc,lw=1.5,alpha=1)  \n",
    "      \n",
    "plt.plot([0,1],[0,1],linestyle='--',lw=2,color='rosybrown',alpha=0.8)    \n",
    "plt.xlim([-0.05,1.05])\n",
    "plt.ylim([-0.05,1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='best')   \n",
    "plt.savefig('C:/Users/deven/Desktop/CPIs/compare/image/Compare_Features_ROC.svg')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 画PR曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画PR曲线\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "colorlist = ['red', 'gold', 'purple', 'limegreen', 'darkblue', 'black']\n",
    "\n",
    "for i in range(1): \n",
    "    Ps = []\n",
    "    RPs = []\n",
    "    mean_R = np.linspace(0, 1, 1000)\n",
    "    for j in range(5):\n",
    "        # 读取文件\n",
    "        RAPNameProb = 'C:/Users/deven/Desktop/CPIs/predict/XGB_' + str(j) + 'Prob.csv'\n",
    "        RealAndPredictionProb = pd.read_csv(RAPNameProb, header=None)\n",
    "\n",
    "        Real = RealAndPredictionProb[0]\n",
    "        PredictionProb = RealAndPredictionProb[1]\n",
    "\n",
    "        # 画图\n",
    "        average_precision = average_precision_score(Real, PredictionProb)\n",
    "        precision, recall, _ = precision_recall_curve(Real, PredictionProb)\n",
    "\n",
    "        Ps.append(interp(mean_R, precision, recall))\n",
    "        RPs.append(average_precision)\n",
    "    \n",
    "    # 画均值\n",
    "    mean_P = np.mean(Ps, axis=0)\n",
    "    mean_RPs = np.mean(RPs, axis=0)\n",
    "    plt.plot(mean_P, mean_R,color=colorlist[5],label=r'GraphCPIs(AUPR=%0.4f)'%mean_RPs,lw=1.5,alpha=1)\n",
    "    \n",
    "    Ps = []\n",
    "    RPs = []\n",
    "    mean_R = np.linspace(0, 1, 1000)\n",
    "    for j in range(5):\n",
    "        # 读取文件\n",
    "        RAPNameProb = 'C:/Users/deven/Desktop/CPIs/compare/predict/XGB_G_' + str(j) + 'Prob.csv'\n",
    "        RealAndPredictionProb = pd.read_csv(RAPNameProb, header=None)\n",
    "\n",
    "        Real = RealAndPredictionProb[0]\n",
    "        PredictionProb = RealAndPredictionProb[1]\n",
    "\n",
    "        # 画图\n",
    "        average_precision = average_precision_score(Real, PredictionProb)\n",
    "        precision, recall, _ = precision_recall_curve(Real, PredictionProb)\n",
    "\n",
    "        Ps.append(interp(mean_R, precision, recall))\n",
    "        RPs.append(average_precision)\n",
    "\n",
    "     # 画均值\n",
    "    mean_P = np.mean(Ps, axis=0)\n",
    "    mean_RPs = np.mean(RPs, axis=0)\n",
    "    plt.plot(mean_P, mean_R,linestyle='-.',color=colorlist[3],label=r'GCN(AUPR=%0.4f)'%mean_RPs,lw=1.5,alpha=1)\n",
    "    Ps = []\n",
    "    RPs = []\n",
    "    mean_R = np.linspace(0, 1, 1000)\n",
    "    for j in range(5):\n",
    "        # 读取文件\n",
    "        RAPNameProb = 'C:/Users/deven/Desktop/CPIs/compare/predict/XGB_A_' + str(j) + 'Prob.csv'\n",
    "        RealAndPredictionProb = pd.read_csv(RAPNameProb, header=None)\n",
    "\n",
    "        Real = RealAndPredictionProb[0]\n",
    "        PredictionProb = RealAndPredictionProb[1]\n",
    "\n",
    "        # 画图\n",
    "        average_precision = average_precision_score(Real, PredictionProb)\n",
    "        precision, recall, _ = precision_recall_curve(Real, PredictionProb)\n",
    "\n",
    "        Ps.append(interp(mean_R, precision, recall))\n",
    "        RPs.append(average_precision)\n",
    "\n",
    "     # 画均值\n",
    "    mean_P = np.mean(Ps, axis=0)\n",
    "    mean_RPs = np.mean(RPs, axis=0)\n",
    "    plt.plot(mean_P, mean_R,linestyle='-',color=colorlist[4],label=r'FP+Seq(AUPR=%0.4f)'%mean_RPs,lw=1.5,alpha=1)\n",
    "    \n",
    "    Ps = []\n",
    "    RPs = []\n",
    "    mean_fpr = np.linspace(0, 1, 1000)\n",
    "    for j in range(5):\n",
    "        # 读取文件\n",
    "        RAPNameProb = 'C:/Users/deven/Desktop/CPIs/compare/predict/XGB_N_' + str(j) + 'Prob.csv'\n",
    "        RealAndPredictionProb = pd.read_csv(RAPNameProb, header=None)\n",
    "\n",
    "        Real = RealAndPredictionProb[0]\n",
    "        PredictionProb = RealAndPredictionProb[1]\n",
    "\n",
    "        # 画图\n",
    "        average_precision = average_precision_score(Real, PredictionProb)\n",
    "        precision, recall, _ = precision_recall_curve(Real, PredictionProb)\n",
    "\n",
    "        Ps.append(interp(mean_R, precision, recall))\n",
    "        RPs.append(average_precision)\n",
    "\n",
    "     # 画均值\n",
    "    mean_P = np.mean(Ps, axis=0)\n",
    "    mean_RPs = np.mean(RPs, axis=0)\n",
    "    plt.plot(mean_P, mean_R,linestyle=':',color=colorlist[0],label=r'Grarep(AUPR=%0.4f)'%mean_RPs,lw=1.5,alpha=1)\n",
    "    \n",
    "plt.plot([1,0],[0,1],linestyle='--',lw=2,color='rosybrown',alpha=0.8)    \n",
    "plt.xlim([-0.05,1.05])\n",
    "plt.ylim([-0.05,1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc='best')   \n",
    "plt.savefig('C:/Users/deven/Desktop/CPIs/compare/image/Compare_features_PR.svg')\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
